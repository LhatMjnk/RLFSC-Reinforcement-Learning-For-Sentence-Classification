{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel, AutoTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from src.utils import *\n",
    "from src.model import *\n",
    "from src.env import *\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Current device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'UIT-ViSFD'\n",
    "\n",
    "train_data = pd.read_csv('./Data/' + data_name + '/train.csv').drop(columns=['label', 'index', 'date_time'])\n",
    "test_data = pd.read_csv('./Data/' + data_name + '/test.csv').drop(columns=['label', 'index', 'date_time'])\n",
    "val_data = pd.read_csv('./Data/' + data_name + '/dev.csv').drop(columns=['label', 'index', 'date_time'])\n",
    "\n",
    "train_data['n_star'] = train_data['n_star'] - 1\n",
    "test_data['n_star'] = test_data['n_star'] - 1\n",
    "val_data['n_star'] = val_data['n_star'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data['n_star'].value_counts().sort_index().plot(kind='bar', color=['red', 'blue', 'green'])\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.title('Number of Reviews per Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_frequencies = train_data['n_star'].value_counts(normalize=True).to_dict()\n",
    "label_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_lengths = train_data['comment'].apply(lambda x: len(x.split()))\n",
    "content_lengths.plot(kind='hist', bins=int(content_lengths.std()), range=(0, int(content_lengths.max())), figsize=(10, 6))\n",
    "plt.xlabel('Length of content')\n",
    "plt.ylabel('Number of content')\n",
    "plt.title('Length of content in the dataset')\n",
    "plt.show()\n",
    "\n",
    "print(content_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['content_length'] = train_data['comment'].apply(lambda x: len(x.split()))\n",
    "\n",
    "max_content_length = train_data['content_length'].max()  # Define the maximum content length\n",
    "\n",
    "for i in train_data['n_star'].unique():  # Iterate over unique n_star values directly\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Optional: Consider a different approach for determining bins, e.g., fixed number or sqrt rule\n",
    "    length_bins = int(np.sqrt(len(train_data[train_data['n_star'] == i])))  # Example alternative\n",
    "    plt.hist(train_data[train_data['n_star'] == i]['content_length'], bins=length_bins, alpha=0.7, label=f'n_star {i}', range=(0, max_content_length))\n",
    "    plt.xlabel('Length of content')\n",
    "    plt.ylabel('Number of content')\n",
    "    plt.title('Length of content in the dataset')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color='black').generate(' '.join(train_data['comment']))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(set(' '.join(train_data['comment']).split()))\n",
    "print('Number of words in the dataset:', num_words)\n",
    "\n",
    "word_freq = Counter(' '.join(train_data['comment']).split()).most_common(num_words)\n",
    "word_freq_df = pd.DataFrame(word_freq, columns=['word', 'frequency'])\n",
    "word_freq_df['frequency'] = word_freq_df['frequency'].astype(int)\n",
    "bins = int(word_freq_df['frequency'].mean())\n",
    "\n",
    "word_freq_df['frequency'].plot(kind='hist', bins=bins, range=(0, bins), figsize=(10, 5))\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Number of words')\n",
    "plt.title('Frequency of words in the dataset')\n",
    "plt.show()\n",
    "print(word_freq_df['frequency'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "val_data = val_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "MAX_LEN = 50\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "encode_data = lambda x: tokenizer(x, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "\n",
    "train_data_comment = encode_data(train_data['comment'].tolist())\n",
    "test_data_comment = encode_data(test_data['comment'].tolist())\n",
    "val_data_comment = encode_data(val_data['comment'].tolist())\n",
    "\n",
    "train_labels = torch.tensor(train_data['n_star']).long()\n",
    "test_labels = torch.tensor(test_data['n_star']).long()\n",
    "val_labels = torch.tensor(val_data['n_star']).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_data_comment['input_ids'], train_data_comment['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_data_comment['input_ids'], test_data_comment['attention_mask'], test_labels)\n",
    "val_dataset = TensorDataset(val_data_comment['input_ids'], val_data_comment['attention_mask'], val_labels)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader.dataset.tensors[0].shape, val_dataloader.dataset.tensors[0].shape, test_dataloader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_data = tokenizer.batch_encode_plus(train_data['comment'].values.tolist(), \n",
    "                                          max_length=MAX_LEN, \n",
    "                                          truncation=True,\n",
    "                                          padding='max_length', \n",
    "                                          return_tensors='pt')\n",
    "\n",
    "indexs, counts = np.unique(encode_data['input_ids'], return_counts=True)\n",
    "\n",
    "print('Percent of UNK token:', counts[indexs == tokenizer.unk_token_id].sum() / np.sum(counts) * 100)\n",
    "print('Percent of PAD token:', counts[indexs == tokenizer.pad_token_id].sum() / np.sum(counts) * 100)\n",
    "print('Percent of CLS token:', counts[indexs == tokenizer.cls_token_id].sum() / np.sum(counts) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentRLSentimentClassifier:\n",
    "    \"\"\"\n",
    "    A reinforcement learning agent for sentiment classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_class, \n",
    "                 actor_critic_net: ActorCriticNet, classifier_net: Classifier, feature_extracter,\n",
    "                 lr_actor_critic=1e-3, lr_classifier=1e-3, gamma=0.99, device='cpu'):\n",
    "        \n",
    "        self.num_class = num_class\n",
    "\n",
    "        self.actor_critic_net = actor_critic_net\n",
    "        self.classifier_net = classifier_net\n",
    "        self.feature_extracter = feature_extracter\n",
    "\n",
    "        self.optimizer_actor_critic = optim.RMSprop(actor_critic_net.parameters(), lr=lr_actor_critic, weight_decay=1e-5)\n",
    "        self.optimizer_classifier = optim.Adam(classifier_net.parameters(), lr=lr_classifier, weight_decay=1e-5)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_decay = 0.9\n",
    "    \n",
    "    def step(self, batches_sentence: torch.Tensor, batches_label: torch.Tensor, batches_attention_mask: torch.Tensor, training=True):\n",
    "        eps = self.epsilon if training else 0\n",
    "\n",
    "        batches_label = batches_label.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            batches_sentence_embedding = self.feature_extracter(batches_sentence.to(self.device, dtype=torch.long), \\\n",
    "                                                                attention_mask=batches_attention_mask.to(self.device, dtype=torch.long))[0]\n",
    "        batch_size, max_len = batches_sentence.shape\n",
    "\n",
    "        noise = torch.randn_like(batches_sentence_embedding) * 0.1\n",
    "        values, policy = self.actor_critic_net(batches_sentence_embedding + noise) # (batch_size, max_len, 1) and (batch_size, max_len, num_actions)\n",
    "        action = self._choose_action(policy, eps)\n",
    "        # print(action.shape)\n",
    "        \n",
    "        filtered_batches_sentence_embedding = batches_sentence_embedding * action.unsqueeze(-1) + noise\n",
    "        # filtered_batches_sentence_embedding = action.unsqueeze(-1).float()\n",
    "        next_values, _ = self.actor_critic_net(filtered_batches_sentence_embedding)\n",
    "\n",
    "\n",
    "        classifier_probs = self.classifier_net(filtered_batches_sentence_embedding)\n",
    "        classifier_loss = F.cross_entropy(classifier_probs, batches_label)\n",
    "\n",
    "        correct_predictions = (classifier_probs.argmax(dim=-1) == batches_label).float()\n",
    "        rewards = self._get_reward(classifier_probs, batches_label).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        with torch.no_grad():  # Don't backpropagate through target calculation\n",
    "            td_target = rewards + self.gamma * next_values\n",
    "            \n",
    "        advantage = td_target - values\n",
    "        log_probs = torch.log(policy) # Log probs for chosen actions\n",
    "        actor_loss = -torch.sum(log_probs * action.unsqueeze(-1), dim=-1)\n",
    "        actor_loss = (actor_loss.unsqueeze(-1) * advantage.detach()).mean()\n",
    "        actor_critic_loss = actor_loss + classifier_loss\n",
    "\n",
    "        accuracy = correct_predictions.mean()\n",
    "        \n",
    "        return actor_critic_loss, classifier_loss, accuracy, rewards.mean().item()\n",
    "    \n",
    "    def _choose_action(self, policy, epsilon):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return torch.randint(0, policy.shape[-1], policy.shape[:-1]).to(self.device)\n",
    "        \n",
    "        return torch.distributions.Categorical(policy).sample()\n",
    "\n",
    "    def _get_reward(self, predicted_probs, true_labels):\n",
    "        true_class_probs = F.one_hot(true_labels, num_classes=self.num_class).float()\n",
    "        rewards = -F.kl_div(predicted_probs, true_class_probs, reduction='batchmean')#.sum(dim=-1)\n",
    "        # print(rewards)\n",
    "        return rewards     \n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader, n_epochs=10):\n",
    "        best_val_loss = float('inf')\n",
    "        epoch = 0\n",
    "        self.training_ac_losses, self.training_classifier_losses, self.training_accuracies, self.training_rewards = [], [], [], []\n",
    "        self.val_ac_losses, self.val_classifier_losses, self.val_accuracies, self.val_rewards = [], [], [], []\n",
    "        while epoch < n_epochs:\n",
    "            print('-' * 50)\n",
    "            print(f'Epoch: {epoch + 1} / {n_epochs}')\n",
    "            self.actor_critic_net.train()\n",
    "            self.classifier_net.train()\n",
    "            running_ac_loss, running_classifier_loss, running_accuracy, running_reward = 0.0, 0.0, 0.0, 0.0\n",
    "            for i, data in enumerate(tqdm.tqdm(train_dataloader), 0):\n",
    "                ac_loss, classifier_loss, accuracy, reward = self.step(data[0], data[2], data[1])\n",
    "\n",
    "                self.optimizer_actor_critic.zero_grad()\n",
    "                self.optimizer_classifier.zero_grad()\n",
    "                # ac_loss.backward()\n",
    "                \n",
    "\n",
    "                total_loss = ac_loss + classifier_loss\n",
    "                total_loss.backward()\n",
    "\n",
    "                self.optimizer_actor_critic.step()\n",
    "\n",
    "                if epoch % 2 == 0:\n",
    "                    # classifier_loss.backward()\n",
    "                    self.optimizer_classifier.step()\n",
    "\n",
    "                running_ac_loss += ac_loss.item()\n",
    "                running_classifier_loss += classifier_loss.item()\n",
    "                running_accuracy += accuracy\n",
    "                running_reward += reward\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "            self.epsilon = max(0.1, self.epsilon * self.epsilon_decay)\n",
    "            \n",
    "            self.training_classifier_losses.append(running_classifier_loss / len(train_dataloader))\n",
    "            self.training_ac_losses.append(running_ac_loss / len(train_dataloader))\n",
    "            self.training_accuracies.append(running_accuracy / len(train_dataloader))\n",
    "            self.training_rewards.append(running_reward / len(train_dataloader))\n",
    "\n",
    "            self.actor_critic_net.eval()\n",
    "            self.classifier_net.eval()\n",
    "            val_ac_loss, val_classifier_loss, val_accuracy, val_reward = 0.0, 0.0, 0.0, 0.0\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(val_dataloader, 0):\n",
    "                    ac_loss, classifier_loss, accuracy, reward = self.step(data[0], data[2], data[1], training=False)\n",
    "                    val_ac_loss += ac_loss.item()\n",
    "                    val_classifier_loss += classifier_loss.item()\n",
    "                    val_accuracy += accuracy\n",
    "                    val_reward += reward\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            self.val_classifier_losses.append(val_classifier_loss / len(val_dataloader))\n",
    "            self.val_ac_losses.append(val_ac_loss / len(val_dataloader))\n",
    "            self.val_accuracies.append(val_accuracy / len(val_dataloader))\n",
    "            self.val_rewards.append(val_reward / len(val_dataloader))\n",
    "\n",
    "            print(f'Training AC Loss: {running_ac_loss / len(train_dataloader) :.2f}, Training Classifier Loss: {running_classifier_loss / len(train_dataloader) :.2f}, Training Accuracy: {running_accuracy / len(train_dataloader) :.2f}, Training Reward: {running_reward / len(train_dataloader) :.2f}, Epsilon: {self.epsilon:.2f}')\n",
    "            print(f'Validation AC Loss: {val_ac_loss / len(val_dataloader) :.2f}, Validation Classifier Loss: {val_classifier_loss / len(val_dataloader) :.2f}, Validation Accuracy: {val_accuracy / len(val_dataloader) :.2f}, Validation Reward: {val_reward / len(val_dataloader) :.2f}')\n",
    "\n",
    "            if val_classifier_loss < best_val_loss:\n",
    "                best_val_loss = val_classifier_loss\n",
    "                torch.save(self.actor_critic_net.state_dict(), './Model/actor_critic_model.pth')\n",
    "                torch.save(self.classifier_net.state_dict(), './Model/classifier_model.pth')\n",
    "                print('Model saved.')\n",
    "            \n",
    "            epoch += 1\n",
    "\n",
    "        print('Finished Training')\n",
    "        torch.cuda.empty_cache()\n",
    "        return self.training_ac_losses, self.training_classifier_losses, self.training_accuracies, self.training_rewards, \\\n",
    "               self.val_ac_losses, self.val_classifier_losses, self.val_accuracies, self.val_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class AgentRLSentimentClassifier:\n",
    "    \"\"\"\n",
    "    A reinforcement learning agent for sentiment classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_class, \n",
    "                 actor_net: ActorNet, critic_classifier_net: CriticClassifierNet, feature_extracter,\n",
    "                 lr_actor_critic=1e-3, lr_classifier=1e-3, gamma=0.99, device='cpu'):\n",
    "        \n",
    "        self.num_class = num_class\n",
    "\n",
    "        self.actor_net = actor_net\n",
    "        self.critic_classifier_net = critic_classifier_net\n",
    "        self.feature_extracter = feature_extracter\n",
    "\n",
    "        self.optimizer_actor_net = optim.RMSprop(self.actor_net.parameters(), lr=lr_actor_critic, weight_decay=1e-5)\n",
    "        self.optimizer_critic_classifier = optim.Adam(self.critic_classifier_net.parameters(), lr=lr_classifier, weight_decay=1e-5)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_decay = 0.9\n",
    "\n",
    "        self.reward_weights = self._calculate_reward_weights().to(device)\n",
    "        print('Reward weights:', self.reward_weights)\n",
    "    \n",
    "    def _calculate_reward_weights(self):\n",
    "        total_samples = sum(label_frequencies.values())\n",
    "        reward_weights = torch.tensor([total_samples / (label_frequencies[label] * len(label_frequencies)) for label in sorted(label_frequencies)], dtype=torch.float)\n",
    "        return reward_weights\n",
    "    \n",
    "    def step(self, \n",
    "             batches_sentence: torch.Tensor, \n",
    "             batches_label: torch.Tensor, \n",
    "             batches_attention_mask: torch.Tensor, \n",
    "             training=True) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, float]:\n",
    "        eps = self.epsilon if training else 0\n",
    "\n",
    "        batches_label = batches_label.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            batches_sentence_embedding = self.feature_extracter(batches_sentence.to(self.device, dtype=torch.long), \\\n",
    "                                                                attention_mask=batches_attention_mask.to(self.device, dtype=torch.long))[0]\n",
    "\n",
    "        policy = self.actor_net.forward(batches_sentence_embedding)\n",
    "        values, _ = self.critic_classifier_net.forward(batches_sentence_embedding)\n",
    "        action = self._choose_action(policy, eps)\n",
    "        \n",
    "        filtered_batches_sentence_embedding = batches_sentence_embedding * action.unsqueeze(-1).float()\n",
    "        # filtered_batches_sentence_embedding = action.unsqueeze(-1).float()\n",
    "        next_values, classifier_probs = self.critic_classifier_net.forward(filtered_batches_sentence_embedding)\n",
    "\n",
    "        classifier_loss = F.cross_entropy(classifier_probs, batches_label)\n",
    "\n",
    "        correct_predictions = (classifier_probs.argmax(dim=-1) == batches_label).float()\n",
    "        accuracy = correct_predictions.mean()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            rewards = self._get_reward(correct_predictions, batches_label)\n",
    "            td_target = rewards + self.gamma * next_values.detach()\n",
    "            \n",
    "        advantage = td_target - values\n",
    "        actor_loss = -(policy.log() * action.unsqueeze(-1)).sum(dim=-1)\n",
    "        actor_loss = (actor_loss.unsqueeze(-1) * advantage.detach()).mean()\n",
    "        actor_critic_loss = actor_loss + classifier_loss\n",
    "        \n",
    "        return actor_critic_loss, classifier_loss, accuracy, rewards.mean().item()\n",
    "    \n",
    "    def _choose_action(self, policy, epsilon):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return torch.randint(0, policy.shape[-1], policy.shape[:-1], device=self.device)\n",
    "        return torch.distributions.Categorical(policy).sample()\n",
    "\n",
    "    def _get_reward(self, correct_predictions, true_labels) -> torch.Tensor:\n",
    "        true_labels_list = true_labels.tolist()\n",
    "        rewards = correct_predictions * self.reward_weights[true_labels_list]\n",
    "        return rewards\n",
    "    \n",
    "    def evaluate(self, dataloader):\n",
    "        self.actor_net.eval()\n",
    "        self.critic_classifier_net.eval()\n",
    "        running_ac_loss, running_classifier_loss, running_accuracy, running_reward = 0.0, 0.0, 0.0, 0.0\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(dataloader, 0):\n",
    "                ac_loss, classifier_loss, accuracy, reward = self.step(data[0], data[2], data[1], training=False)\n",
    "                running_ac_loss += ac_loss.item()\n",
    "                running_classifier_loss += classifier_loss.item()\n",
    "                running_accuracy += accuracy\n",
    "                running_reward += reward\n",
    "\n",
    "                preds = self.critic_classifier_net.forward(self.feature_extracter(data[0].to(self.device, dtype=torch.long), \\\n",
    "                                                                                       attention_mask=data[1].to(self.device, dtype=torch.long))[0])[1].argmax(dim=-1).tolist()\n",
    "\n",
    "                y_true.extend(data[2].tolist())\n",
    "                y_pred.extend(preds)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        return running_ac_loss / len(dataloader), \\\n",
    "               running_classifier_loss / len(dataloader), \\\n",
    "               running_accuracy / len(dataloader), \\\n",
    "               running_reward / len(dataloader), \\\n",
    "               f1\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader, n_epochs=10):\n",
    "        best_val_loss = float('inf')\n",
    "        epoch = 0\n",
    "        self.training_ac_losses, self.training_classifier_losses, self.training_accuracies, self.training_rewards = [], [], [], []\n",
    "        self.val_ac_losses, self.val_classifier_losses, self.val_accuracies, self.val_rewards = [], [], [], []\n",
    "        while epoch < n_epochs:\n",
    "            print('-' * 50)\n",
    "            print(f'Epoch: {epoch + 1} / {n_epochs}')\n",
    "\n",
    "            # ---------------------- Training ---------------------- #\n",
    "            self.actor_net.train()\n",
    "            self.critic_classifier_net.train()\n",
    "            running_ac_loss, running_classifier_loss, running_accuracy, running_reward = 0.0, 0.0, 0.0, 0.0\n",
    "            for i, data in enumerate(tqdm.tqdm(train_dataloader), 0):\n",
    "                ac_loss, classifier_loss, accuracy, reward = self.step(data[0], data[2], data[1])\n",
    "\n",
    "                self.optimizer_actor_net.zero_grad()\n",
    "                self.optimizer_critic_classifier.zero_grad()\n",
    "                # ac_loss.backward()\n",
    "\n",
    "                total_loss = ac_loss + classifier_loss\n",
    "                total_loss.backward()\n",
    "\n",
    "                self.optimizer_actor_net.step()\n",
    "                self.optimizer_critic_classifier.step()\n",
    "\n",
    "                running_ac_loss += ac_loss.item()\n",
    "                running_classifier_loss += classifier_loss.item()\n",
    "                running_accuracy += accuracy\n",
    "                running_reward += reward\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "            self.epsilon = max(0.1, self.epsilon * self.epsilon_decay)\n",
    "            \n",
    "            self.training_classifier_losses.append(running_classifier_loss / len(train_dataloader))\n",
    "            self.training_ac_losses.append(running_ac_loss / len(train_dataloader))\n",
    "            self.training_accuracies.append(running_accuracy / len(train_dataloader))\n",
    "            self.training_rewards.append(running_reward / len(train_dataloader))\n",
    "\n",
    "            # ---------------------- Validation ---------------------- #\n",
    "            val_ac_loss, val_classifier_loss, val_accuracy, val_reward, val_f1 = self.evaluate(val_dataloader)\n",
    "\n",
    "            self.val_classifier_losses.append(val_classifier_loss)\n",
    "            self.val_ac_losses.append(val_ac_loss)\n",
    "            self.val_accuracies.append(val_accuracy)\n",
    "            self.val_rewards.append(val_reward)\n",
    "\n",
    "\n",
    "            print(f'Training AC Loss: {running_ac_loss / len(train_dataloader) :.2f}, Training Classifier Loss: {running_classifier_loss / len(train_dataloader) :.2f}, Training Accuracy: {running_accuracy / len(train_dataloader) :.2f}, Training Reward: {running_reward / len(train_dataloader) :.2f}, Epsilon: {self.epsilon:.2f}')\n",
    "            print(f'Validation AC Loss: {val_ac_loss :.2f}, Validation Classifier Loss: {val_classifier_loss :.2f}, Validation Accuracy: {val_accuracy :.2f}, Validation Reward: {val_reward :.2f}, Validation F1: {val_f1 :.2f}')\n",
    "\n",
    "            if val_classifier_loss < best_val_loss:\n",
    "                best_val_loss = val_classifier_loss\n",
    "                torch.save(self.actor_net.state_dict(), './Model/actor_model_'+ data_name +'.pth')\n",
    "                torch.save(self.critic_classifier_net.state_dict(), './Model/critic_classifier_model_'+ data_name +'.pth')\n",
    "                print('Model saved.')\n",
    "            \n",
    "            epoch += 1\n",
    "\n",
    "        print('Finished Training')\n",
    "        torch.cuda.empty_cache()\n",
    "        return self.training_ac_losses, self.training_classifier_losses, self.training_accuracies, self.training_rewards, \\\n",
    "               self.val_ac_losses, self.val_classifier_losses, self.val_accuracies, self.val_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import ActorNet, CriticClassifierNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class = 5\n",
    "# actor_critic_net = ActorCriticNet(input_dim=768, output_dim=2).to(device)\n",
    "# classifier_net = Classifier(input_dim=768, output_dim=num_class).to(device)\n",
    "# feature_extracter = phobert.to(device)\n",
    "# feature_extracter.eval()\n",
    "\n",
    "# agent = AgentRLSentimentClassifier(num_class=num_class, actor_critic_net=actor_critic_net, classifier_net=classifier_net, feature_extracter=feature_extracter, device=device, \n",
    "#                                    lr_actor_critic=1e-4, lr_classifier=1e-5, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 5\n",
    "actor_net = ActorNet(input_dim=768, output_dim=2).to(device)\n",
    "critic_classifier_net = CriticClassifierNet(input_dim=768, seq_len=MAX_LEN, output_dim=num_class).to(device)\n",
    "feature_extracter = phobert.to(device)\n",
    "feature_extracter.eval()\n",
    "\n",
    "agent = AgentRLSentimentClassifier(num_class=num_class, actor_net=actor_net, critic_classifier_net=critic_classifier_net, \n",
    "                                   feature_extracter=feature_extracter, device=device, \n",
    "                                   lr_actor_critic=1e-5, lr_classifier=2e-5, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ac_losses, training_classifier_losses, training_accuracy, training_rewards, \\\n",
    "val_ac_losses, val_classifier_losses, val_accuracy, val_rewards = agent.train(train_dataloader, \n",
    "                                                                              val_dataloader, \n",
    "                                                                              n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(agent.training_ac_losses, label='Train AC Loss')\n",
    "plt.plot(agent.val_ac_losses, label='Val AC Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(agent.training_classifier_losses, label='Train CLS Loss')\n",
    "plt.plot(agent.val_classifier_losses, label='Val CLS Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rewards = torch.tensor(agent.training_rewards)\n",
    "training_rewards.tolist()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_rewards.tolist(), label='Train Rewards')\n",
    "plt.plot(torch.tensor(agent.val_rewards).cpu(), label='Val Rewards')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Rewards')\n",
    "plt.title('Training and Validation Rewards')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = torch.tensor(agent.training_accuracies).cpu()\n",
    "val_accuracy = torch.tensor(agent.val_accuracies).cpu()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_accuracy, label='Train Accuracy')\n",
    "plt.plot(val_accuracy, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(actor_model, critic_classifier_model, dataloader):\n",
    "    actor_model.eval()\n",
    "    critic_classifier_model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm.tqdm(dataloader), 0):\n",
    "            sentence_embedding = phobert(data[0].to(device), attention_mask=data[1].to(device))[0]\n",
    "            policy = actor_model(sentence_embedding)\n",
    "            action = torch.argmax(policy, dim=-1)\n",
    "            filtered_sentence_embedding = sentence_embedding * action.unsqueeze(-1).float()\n",
    "            _, classifier_preds = critic_classifier_model(filtered_sentence_embedding)\n",
    "            preds.extend(classifier_preds.argmax(dim=-1).cpu().numpy())\n",
    "            labels.extend(data[2].cpu().numpy())\n",
    "    return preds, labels\n",
    "\n",
    "actor_net.load_state_dict(torch.load('./Model/actor_model_'+ data_name +'.pth'))\n",
    "critic_classifier_net.load_state_dict(torch.load('./Model/critic_classifier_model_'+ data_name +'.pth'))\n",
    "\n",
    "test_preds, test_labels = evaluate_model(actor_net, critic_classifier_net, test_dataloader)\n",
    "print(classification_report(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net.eval()\n",
    "actions = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm.tqdm(train_dataloader), 0):\n",
    "        batch_sentences = data[0].to(device)\n",
    "        sentence_embedding = phobert(batch_sentences, attention_mask=data[1].to(device))[0]\n",
    "        policy = actor_net(sentence_embedding)\n",
    "        action = torch.argmax(policy, dim=-1).squeeze()\n",
    "        actions.extend(action.cpu().tolist())\n",
    "\n",
    "action_maked = np.array(actions)\n",
    "action_distribuution = np.unique(action_maked, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_distribuution_data = pd.DataFrame(action_distribuution[1], index=action_distribuution[0], columns=['count'])\n",
    "action_distribuution_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
